{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_py_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf8\") as f:\n",
    "        file_content = f.read()\n",
    "\n",
    "    # Remove import statements\n",
    "    file_content = re.sub(r\"^import.*$|^from .* import.*$\", \"\", file_content, flags=re.MULTILINE)\n",
    "\n",
    "    file_content = re.sub(r\"^sys.path.append.*\\n\", \"\", file_content, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove comments\n",
    "    file_content = re.sub(r\"#.*\", \"\", file_content)\n",
    "\n",
    "    # # Remove function descriptions and docstrings\n",
    "    patron_docstrings_triple_comillas = r'(\\\"\\\"\\\")(.*?)(\\\"\\\"\\\")'\n",
    "    patron_docstrings_comillas_simples = r'(\\'\\'\\')(.*?)(\\'\\'\\')'\n",
    "    patron_total = f\"{patron_docstrings_triple_comillas}|{patron_docstrings_comillas_simples}\"\n",
    "\n",
    "    file_content = re.sub(patron_total, '', file_content, flags=re.DOTALL)\n",
    "\n",
    "    # Remove the code inside if __name__ == \"__main__\": block\n",
    "    file_content = re.sub(r'if __name__ == \"__main__\":[\\s\\S]*', \"\", file_content)\n",
    "\n",
    "    # Remove any empty lines and extra whitespaces\n",
    "    file_content = re.sub(r\"^\\s*\\n\", \"\", file_content, flags=re.MULTILINE)\n",
    "    file_content = re.sub(r\"\\n\\s*\\n\", \"\\n\", file_content)\n",
    "    file_content = file_content.strip()\n",
    "\n",
    "    return file_content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_import_lines(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf8\") as f:\n",
    "        file_content = f.read()\n",
    "\n",
    "    # Find all import lines using regular expression\n",
    "    import_lines = re.findall(r\"^import.*$|^from .* import.*$\", file_content, re.MULTILINE)\n",
    "\n",
    "    return import_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class FATIGUE_LIFE:\n",
      "    def __init__(self, measurements):\n",
      "        self.parameters = self.get_parameters(measurements)\n",
      "        self.gamma = self.parameters[\"gamma\"]\n",
      "        self.loc = self.parameters[\"loc\"]\n",
      "        self.scale = self.parameters[\"scale\"]\n",
      "    def cdf(self, x: float) -> float:\n",
      "        z = lambda t: math.sqrt((t - self.loc) / self.scale)\n",
      "        result = scipy.stats.norm.cdf((z(x) - 1 / z(x)) / (self.gamma))\n",
      "        return result\n",
      "    def pdf(self, x: float) -> float:\n",
      "        z = lambda t: math.sqrt((t - self.loc) / self.scale)\n",
      "        result = (z(x) + 1 / z(x)) / (2 * self.gamma * (x - self.loc)) * scipy.stats.norm.pdf((z(x) - 1 / z(x)) / (self.gamma))\n",
      "        return result\n",
      "    def get_num_parameters(self) -> int:\n",
      "        return len(self.parameters)\n",
      "    def parameter_restrictions(self) -> bool:\n",
      "        v1 = self.scale > 0\n",
      "        v2 = self.gamma > 0\n",
      "        return v1 and v2\n",
      "    def get_parameters(self, measurements) -> dict[str, float | int]:\n",
      "        scipy_params = scipy.stats.fatiguelife.fit(measurements.data)\n",
      "        parameters = {\"gamma\": scipy_params[0], \"loc\": scipy_params[1], \"scale\": scipy_params[2]}\n",
      "        return parameters\n"
     ]
    }
   ],
   "source": [
    "input_file_path = \"../../continuous/distributions/fatigue_life.py\"\n",
    "processed_content = process_py_file(input_file_path)\n",
    "print(processed_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"../../continuous/distributions/fatigue_life.py\"\n",
    "import_lines = get_import_lines(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORTS = []\n",
    "for file in os.listdir(\"../../continuous/distributions\"):\n",
    "    if \".py\" in file:\n",
    "        import_lines = get_import_lines(f\"../../continuous/distributions/{file}\")\n",
    "        IMPORTS.extend(import_lines)\n",
    "\n",
    "input_file_path = \"../../continuous/measurements/measurements_continuous.py\"\n",
    "import_lines = get_import_lines(input_file_path)\n",
    "IMPORTS.extend(import_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE = \"\\n\".join(sorted(list(set(IMPORTS)))) + \"\\n\\n\"\n",
    "for file in os.listdir(\"../../continuous/distributions\"):\n",
    "    if \".py\" in file:\n",
    "        processed_content = process_py_file(f\"../../continuous/distributions/{file}\")\n",
    "        CODE += processed_content + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"../../continuous/measurements/measurements_continuous.py\"\n",
    "measuerements_code = process_py_file(input_file_path)\n",
    "CODE += measuerements_code + \"\\n\\n\"\n",
    "\n",
    "input_file_path = \"../../continuous/test_chi_square_continuous.py\"\n",
    "test_chi_square_continuous_code = process_py_file(input_file_path)\n",
    "CODE += test_chi_square_continuous_code + \"\\n\\n\"\n",
    "\n",
    "input_file_path = \"../../continuous/test_kolmogorov_smirnov_continuous.py\"\n",
    "test_kolmogorov_smirnov_continuous_code = process_py_file(input_file_path)\n",
    "CODE += test_kolmogorov_smirnov_continuous_code + \"\\n\\n\"\n",
    "\n",
    "input_file_path = \"../../utilities/ad_marsaglia.py\"\n",
    "anderson_darling_code = process_py_file(input_file_path)\n",
    "CODE += anderson_darling_code + \"\\n\\n\"\n",
    "\n",
    "input_file_path = \"../../continuous/test_anderson_darling_continuous.py\"\n",
    "test_anderson_darling_continuous_code = process_py_file(input_file_path)\n",
    "test_anderson_darling_continuous_code = test_anderson_darling_continuous_code.replace(\"ad.\", \"\")\n",
    "CODE += test_anderson_darling_continuous_code + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_name = \"\"\"\n",
    "def phitter_continuous(data, num_bins=None, confidence_level=0.95):\n",
    "    _all_distributions = [\n",
    "        ALPHA,\n",
    "        ARCSINE,\n",
    "        ARGUS,\n",
    "        BETA,\n",
    "        BETA_PRIME,\n",
    "        BETA_PRIME_4P,\n",
    "        BRADFORD,\n",
    "        BURR,\n",
    "        BURR_4P,\n",
    "        CAUCHY,\n",
    "        CHI_SQUARE,\n",
    "        CHI_SQUARE_3P,\n",
    "        DAGUM,\n",
    "        DAGUM_4P,\n",
    "        ERLANG,\n",
    "        ERLANG_3P,\n",
    "        ERROR_FUNCTION,\n",
    "        EXPONENTIAL,\n",
    "        EXPONENTIAL_2P,\n",
    "        F,\n",
    "        FATIGUE_LIFE,\n",
    "        FOLDED_NORMAL,\n",
    "        FRECHET,\n",
    "        F_4P,\n",
    "        GAMMA,\n",
    "        GAMMA_3P,\n",
    "        GENERALIZED_EXTREME_VALUE,\n",
    "        GENERALIZED_GAMMA,\n",
    "        GENERALIZED_GAMMA_4P,\n",
    "        GENERALIZED_LOGISTIC,\n",
    "        GENERALIZED_NORMAL,\n",
    "        GENERALIZED_PARETO,\n",
    "        GIBRAT,\n",
    "        GUMBEL_LEFT,\n",
    "        GUMBEL_RIGHT,\n",
    "        HALF_NORMAL,\n",
    "        HYPERBOLIC_SECANT,\n",
    "        INVERSE_GAMMA,\n",
    "        INVERSE_GAMMA_3P,\n",
    "        INVERSE_GAUSSIAN,\n",
    "        INVERSE_GAUSSIAN_3P,\n",
    "        JOHNSON_SB,\n",
    "        JOHNSON_SU,\n",
    "        KUMARASWAMY,\n",
    "        LAPLACE,\n",
    "        LEVY,\n",
    "        LOGGAMMA,\n",
    "        LOGISTIC,\n",
    "        LOGLOGISTIC,\n",
    "        LOGLOGISTIC_3P,\n",
    "        LOGNORMAL,\n",
    "        MAXWELL,\n",
    "        MOYAL,\n",
    "        NAKAGAMI,\n",
    "        NON_CENTRAL_CHI_SQUARE,\n",
    "        NON_CENTRAL_F,\n",
    "        NON_CENTRAL_T_STUDENT,\n",
    "        NORMAL,\n",
    "        PARETO_FIRST_KIND,\n",
    "        PARETO_SECOND_KIND,\n",
    "        PERT,\n",
    "        POWER_FUNCTION,\n",
    "        RAYLEIGH,\n",
    "        RECIPROCAL,\n",
    "        RICE,\n",
    "        SEMICIRCULAR,\n",
    "        TRAPEZOIDAL,\n",
    "        TRIANGULAR,\n",
    "        T_STUDENT,\n",
    "        T_STUDENT_3P,\n",
    "        UNIFORM,\n",
    "        WEIBULL,\n",
    "        WEIBULL_3P,\n",
    "    ]\n",
    "    measurements = MEASUREMENTS_CONTINUOUS(data, num_bins)\n",
    "\n",
    "    ## Calculae Histogram\n",
    "    num_bins = measurements.num_bins\n",
    "    frequencies, bin_edges = numpy.histogram(data, num_bins, density=True)\n",
    "    central_values = [(bin_edges[i] + bin_edges[i + 1]) / 2 for i in range(len(bin_edges) - 1)]\n",
    "\n",
    "    NONE_RESULTS = {\n",
    "        \"test_statistic\": None,\n",
    "        \"critical_value\": None,\n",
    "        \"p_value\": None,\n",
    "        \"rejected\": None,\n",
    "    }\n",
    "\n",
    "    RESPONSE = {}\n",
    "    for distribution_class in _all_distributions:\n",
    "        distribution_name = distribution_class.__name__.lower()\n",
    "\n",
    "        validate_estimation = True\n",
    "        sse = 0\n",
    "        try:\n",
    "            distribution = distribution_class(measurements)\n",
    "            pdf_values = [distribution.pdf(c) for c in central_values]\n",
    "            sse = numpy.sum(numpy.power(frequencies - pdf_values, 2.0))\n",
    "        except:\n",
    "            validate_estimation = False\n",
    "\n",
    "        DISTRIBUTION_RESULTS = {}\n",
    "        v1, v2, v3 = False, False, False\n",
    "        if validate_estimation and not math.isnan(sse) and not math.isinf(sse):\n",
    "            try:\n",
    "                chi2_test = test_chi_square_continuous(data, distribution, measurements, confidence_level=confidence_level)\n",
    "                if numpy.isnan(chi2_test[\"test_statistic\"]) == False and math.isinf(chi2_test[\"test_statistic\"]) == False and chi2_test[\"test_statistic\"] > 0:\n",
    "                    DISTRIBUTION_RESULTS[\"chi_square\"] = {\n",
    "                        \"test_statistic\": chi2_test[\"test_statistic\"],\n",
    "                        \"critical_value\": chi2_test[\"critical_value\"],\n",
    "                        \"p_value\": chi2_test[\"p-value\"],\n",
    "                        \"rejected\": chi2_test[\"rejected\"],\n",
    "                    }\n",
    "                    v1 = True\n",
    "                else:\n",
    "                    DISTRIBUTION_RESULTS[\"chi_square\"] = NONE_RESULTS\n",
    "            except:\n",
    "                DISTRIBUTION_RESULTS[\"chi_square\"] = NONE_RESULTS\n",
    "\n",
    "            try:\n",
    "                ks_test = test_kolmogorov_smirnov_continuous(data, distribution, measurements, confidence_level=confidence_level)\n",
    "                if numpy.isnan(ks_test[\"test_statistic\"]) == False and math.isinf(ks_test[\"test_statistic\"]) == False and ks_test[\"test_statistic\"] > 0:\n",
    "                    DISTRIBUTION_RESULTS[\"kolmogorov_smirnov\"] = {\n",
    "                        \"test_statistic\": ks_test[\"test_statistic\"],\n",
    "                        \"critical_value\": ks_test[\"critical_value\"],\n",
    "                        \"p_value\": ks_test[\"p-value\"],\n",
    "                        \"rejected\": ks_test[\"rejected\"],\n",
    "                    }\n",
    "                    v2 = True\n",
    "                else:\n",
    "                    DISTRIBUTION_RESULTS[\"anderson_darling\"] = NONE_RESULTS\n",
    "            except:\n",
    "                DISTRIBUTION_RESULTS[\"kolmogorov_smirnov\"] = NONE_RESULTS\n",
    "            try:\n",
    "                ad_test = test_anderson_darling_continuous(data, distribution, measurements, confidence_level=confidence_level)\n",
    "                if numpy.isnan(ad_test[\"test_statistic\"]) == False and math.isinf(ad_test[\"test_statistic\"]) == False and ad_test[\"test_statistic\"] > 0:\n",
    "                    DISTRIBUTION_RESULTS[\"anderson_darling\"] = {\n",
    "                        \"test_statistic\": ad_test[\"test_statistic\"],\n",
    "                        \"critical_value\": ad_test[\"critical_value\"],\n",
    "                        \"p_value\": ad_test[\"p-value\"],\n",
    "                        \"rejected\": ad_test[\"rejected\"],\n",
    "                    }\n",
    "                    v3 = True\n",
    "                else:\n",
    "                    DISTRIBUTION_RESULTS[\"anderson_darling\"] = NONE_RESULTS\n",
    "            except:\n",
    "                DISTRIBUTION_RESULTS[\"anderson_darling\"] = NONE_RESULTS\n",
    "\n",
    "            if v1 or v2 or v3:\n",
    "                DISTRIBUTION_RESULTS[\"sse\"] = sse\n",
    "                DISTRIBUTION_RESULTS[\"parameters\"] = str(distribution.parameters)\n",
    "                DISTRIBUTION_RESULTS[\"n_test_passed\"] = (\n",
    "                    int(DISTRIBUTION_RESULTS[\"chi_square\"][\"rejected\"] == False)\n",
    "                    + int(DISTRIBUTION_RESULTS[\"kolmogorov_smirnov\"][\"rejected\"] == False)\n",
    "                    + int(DISTRIBUTION_RESULTS[\"anderson_darling\"][\"rejected\"] == False)\n",
    "                )\n",
    "                DISTRIBUTION_RESULTS[\"n_test_null\"] = (\n",
    "                    int(DISTRIBUTION_RESULTS[\"chi_square\"][\"rejected\"] == None)\n",
    "                    + int(DISTRIBUTION_RESULTS[\"kolmogorov_smirnov\"][\"rejected\"] == None)\n",
    "                    + int(DISTRIBUTION_RESULTS[\"anderson_darling\"][\"rejected\"] == None)\n",
    "                )\n",
    "\n",
    "                RESPONSE[distribution_name] = DISTRIBUTION_RESULTS\n",
    "\n",
    "    sorted_results_sse = {distribution: results for distribution, results in sorted(RESPONSE.items(), key=lambda x: x[1][\"sse\"])}\n",
    "    aproved_results = {distribution: results for distribution, results in sorted_results_sse.items() if results[\"n_test_passed\"] > 0}\n",
    "\n",
    "    return sorted_results_sse, aproved_results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = \"../../continuous/data/data_beta.txt\"\n",
    "    sample_distribution_file = open(path, \"r\")\n",
    "    data = [float(x.replace(\",\", \".\")) for x in sample_distribution_file.read().splitlines()]\n",
    "\n",
    "    sorted_results_sse, aproved_results = phitter_continuous(data, 20, confidence_level=0.99)\n",
    "\n",
    "    for distribution, results in aproved_results.items():\n",
    "        print(f\"Distribution: {distribution}, SSE: {results['sse']}, Aprobados: {results['n_test_passed']}\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE += if_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_file = open(\"./code_continuous.py\", \"+w\", encoding=\"utf8\")\n",
    "code_file.write(CODE)\n",
    "code_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
