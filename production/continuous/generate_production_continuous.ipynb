{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_py_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf8\") as f:\n",
    "        file_content = f.read()\n",
    "\n",
    "    # Remove import statements\n",
    "    file_content = re.sub(r\"^import.*$|^from .* import.*$\", \"\", file_content, flags=re.MULTILINE)\n",
    "\n",
    "    file_content = re.sub(r\"^sys.path.append.*\\n\", \"\", file_content, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove comments\n",
    "    file_content = re.sub(r\"#.*\", \"\", file_content)\n",
    "\n",
    "    # # Remove function descriptions and docstrings\n",
    "    patron_docstrings_triple_comillas = r\"(\\\"\\\"\\\")(.*?)(\\\"\\\"\\\")\"\n",
    "    patron_docstrings_comillas_simples = r\"(\\'\\'\\')(.*?)(\\'\\'\\')\"\n",
    "    patron_total = f\"{patron_docstrings_triple_comillas}|{patron_docstrings_comillas_simples}\"\n",
    "\n",
    "    file_content = re.sub(patron_total, \"\", file_content, flags=re.DOTALL)\n",
    "\n",
    "    # Remove the code inside if __name__ == \"__main__\": block\n",
    "    file_content = re.sub(r'if __name__ == \"__main__\":[\\s\\S]*', \"\", file_content)\n",
    "\n",
    "    # Remove any empty lines and extra whitespaces\n",
    "    file_content = re.sub(r\"^\\s*\\n\", \"\", file_content, flags=re.MULTILINE)\n",
    "    file_content = re.sub(r\"\\n\\s*\\n\", \"\\n\", file_content)\n",
    "    file_content = file_content.strip()\n",
    "\n",
    "    return file_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_import_lines(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf8\") as f:\n",
    "        file_content = f.read()\n",
    "\n",
    "    # Find all import lines using regular expression\n",
    "    import_lines = re.findall(r\"^import.*$|^from .* import.*$\", file_content, re.MULTILINE)\n",
    "\n",
    "    return import_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class FATIGUE_LIFE:\n",
      "    def __init__(self, measurements):\n",
      "        self.parameters = self.get_parameters(measurements)\n",
      "        self.gamma = self.parameters[\"gamma\"]\n",
      "        self.loc = self.parameters[\"loc\"]\n",
      "        self.scale = self.parameters[\"scale\"]\n",
      "    def cdf(self, x: float) -> float:\n",
      "        z = lambda t: numpy.sqrt((t - self.loc) / self.scale)\n",
      "        result = scipy.stats.norm.cdf((z(x) - 1 / z(x)) / (self.gamma))\n",
      "        return result\n",
      "    def pdf(self, x: float) -> float:\n",
      "        z = lambda t: numpy.sqrt((t - self.loc) / self.scale)\n",
      "        result = (z(x) + 1 / z(x)) / (2 * self.gamma * (x - self.loc)) * scipy.stats.norm.pdf((z(x) - 1 / z(x)) / (self.gamma))\n",
      "        return result\n",
      "    def get_num_parameters(self) -> int:\n",
      "        return len(self.parameters)\n",
      "    def parameter_restrictions(self) -> bool:\n",
      "        v1 = self.scale > 0\n",
      "        v2 = self.gamma > 0\n",
      "        return v1 and v2\n",
      "    def get_parameters(self, measurements) -> dict[str, float | int]:\n",
      "        scipy_params = scipy.stats.fatiguelife.fit(measurements.data)\n",
      "        parameters = {\"gamma\": scipy_params[0], \"loc\": scipy_params[1], \"scale\": scipy_params[2]}\n",
      "        return parameters\n"
     ]
    }
   ],
   "source": [
    "input_file_path = \"../../continuous/distributions/fatigue_life.py\"\n",
    "processed_content = process_py_file(input_file_path)\n",
    "print(processed_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"../../continuous/distributions/fatigue_life.py\"\n",
    "import_lines = get_import_lines(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORTS = []\n",
    "for file in os.listdir(\"../../continuous/distributions\"):\n",
    "    if \".py\" in file:\n",
    "        import_lines = get_import_lines(f\"../../continuous/distributions/{file}\")\n",
    "        IMPORTS.extend(import_lines)\n",
    "\n",
    "input_file_path = \"../../continuous/measurements/measurements_continuous.py\"\n",
    "import_lines = get_import_lines(input_file_path)\n",
    "IMPORTS.extend(import_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORTS.append(\"import joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE = \"\\n\".join(sorted(list(set(IMPORTS)))) + \"\\n\\n\"\n",
    "for file in os.listdir(\"../../continuous/distributions\"):\n",
    "    if \".py\" in file:\n",
    "        processed_content = process_py_file(f\"../../continuous/distributions/{file}\")\n",
    "        CODE += processed_content + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"../../continuous/measurements/measurements_continuous.py\"\n",
    "measuerements_code = process_py_file(input_file_path)\n",
    "CODE += measuerements_code + \"\\n\\n\"\n",
    "\n",
    "input_file_path = \"../../continuous/test_chi_square_continuous.py\"\n",
    "test_chi_square_continuous_code = process_py_file(input_file_path)\n",
    "CODE += test_chi_square_continuous_code + \"\\n\\n\"\n",
    "\n",
    "input_file_path = \"../../continuous/test_kolmogorov_smirnov_continuous.py\"\n",
    "test_kolmogorov_smirnov_continuous_code = process_py_file(input_file_path)\n",
    "CODE += test_kolmogorov_smirnov_continuous_code + \"\\n\\n\"\n",
    "\n",
    "# input_file_path = \"../../utilities/ad_marsaglia.py\"\n",
    "# anderson_darling_code = process_py_file(input_file_path)\n",
    "# CODE += anderson_darling_code + \"\\n\\n\"\n",
    "\n",
    "input_file_path = \"../../continuous/test_anderson_darling_continuous.py\"\n",
    "test_anderson_darling_continuous_code = process_py_file(input_file_path)\n",
    "test_anderson_darling_continuous_code = test_anderson_darling_continuous_code.replace(\"ad.\", \"\")\n",
    "CODE += test_anderson_darling_continuous_code + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_phitter_continuous_code = process_py_file(\"../../phitter/continuous/phitter_continuous.py\")\n",
    "CODE += class_phitter_continuous_code + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class PHITTER_CONTINUOUS:\\n    def __init__(\\n        self,\\n        data: list[int | float],\\n        num_bins: int | None = None,\\n        confidence_level=0.95,\\n        minimum_sse=float(\"inf\"),\\n    ):\\n        self.data = data\\n        self.measurements = MEASUREMENTS_CONTINUOUS(self.data, num_bins, confidence_level)\\n        self.confidence_level = confidence_level\\n        self.minimum_sse = minimum_sse\\n        self.distribution_results = {}\\n        self.none_results = {\"test_statistic\": None, \"critical_value\": None, \"p_value\": None, \"rejected\": None}\\n    def test(self, test_function, label: str, distribution):\\n        validation_test = False\\n        try:\\n            test = test_function(distribution, self.measurements, confidence_level=self.confidence_level)\\n            if numpy.isnan(test[\"test_statistic\"]) == False and numpy.isinf(test[\"test_statistic\"]) == False and test[\"test_statistic\"] > 0:\\n                self.distribution_results[label] = {\\n                    \"test_statistic\": test[\"test_statistic\"],\\n                    \"critical_value\": test[\"critical_value\"],\\n                    \"p_value\": test[\"p-value\"],\\n                    \"rejected\": test[\"rejected\"],\\n                }\\n                validation_test = True\\n            else:\\n                self.distribution_results[label] = self.none_results\\n        except:\\n            self.distribution_results[label] = self.none_results\\n        return validation_test\\n    def process_distribution(self, distribution_class):\\n        distribution_name = distribution_class.__name__.lower()\\n        validate_estimation = True\\n        sse = 0\\n        try:\\n            distribution = distribution_class(self.measurements)\\n            pdf_values = [distribution.pdf(c) for c in self.measurements.central_values]\\n            sse = numpy.sum(numpy.power(self.measurements.densities_frequencies - pdf_values, 2.0))\\n        except:\\n            validate_estimation = False\\n        self.distribution_results = {}\\n        if validate_estimation and distribution.parameter_restrictions() and not numpy.isnan(sse) and not numpy.isinf(sse) and sse < self.minimum_sse:\\n            v1 = self.test(test_chi_square_continuous, \"chi_square\", distribution)\\n            v2 = self.test(test_kolmogorov_smirnov_continuous, \"kolmogorov_smirnov\", distribution)\\n            v3 = self.test(test_anderson_darling_continuous, \"anderson_darling\", distribution)\\n            if v1 or v2 or v3:\\n                self.distribution_results[\"sse\"] = sse\\n                self.distribution_results[\"parameters\"] = str(distribution.parameters)\\n                self.distribution_results[\"n_test_passed\"] = (\\n                    +int(self.distribution_results[\"chi_square\"][\"rejected\"] == False)\\n                    + int(self.distribution_results[\"kolmogorov_smirnov\"][\"rejected\"] == False)\\n                    + int(self.distribution_results[\"anderson_darling\"][\"rejected\"] == False)\\n                )\\n                self.distribution_results[\"n_test_null\"] = (\\n                    +int(self.distribution_results[\"chi_square\"][\"rejected\"] == None)\\n                    + int(self.distribution_results[\"kolmogorov_smirnov\"][\"rejected\"] == None)\\n                    + int(self.distribution_results[\"anderson_darling\"][\"rejected\"] == None)\\n                )\\n                return distribution_name, self.distribution_results\\n        return None\\n    def fit(self, n_jobs: int = 1):\\n        if n_jobs <= 0:\\n            raise Exception(\"n_jobs must be greater than 1\")\\n        _ALL_CONTINUOUS_DISTRIBUTIONS = [\\n            ALPHA,\\n            ARCSINE,\\n            ARGUS,\\n            BETA,\\n            BETA_PRIME,\\n            BETA_PRIME_4P,\\n            BRADFORD,\\n            BURR,\\n            BURR_4P,\\n            CAUCHY,\\n            CHI_SQUARE,\\n            CHI_SQUARE_3P,\\n            DAGUM,\\n            DAGUM_4P,\\n            ERLANG,\\n            ERLANG_3P,\\n            ERROR_FUNCTION,\\n            EXPONENTIAL,\\n            EXPONENTIAL_2P,\\n            F,\\n            FATIGUE_LIFE,\\n            FOLDED_NORMAL,\\n            FRECHET,\\n            F_4P,\\n            GAMMA,\\n            GAMMA_3P,\\n            GENERALIZED_EXTREME_VALUE,\\n            GENERALIZED_GAMMA,\\n            GENERALIZED_GAMMA_4P,\\n            GENERALIZED_LOGISTIC,\\n            GENERALIZED_NORMAL,\\n            GENERALIZED_PARETO,\\n            GIBRAT,\\n            GUMBEL_LEFT,\\n            GUMBEL_RIGHT,\\n            HALF_NORMAL,\\n            HYPERBOLIC_SECANT,\\n            INVERSE_GAMMA,\\n            INVERSE_GAMMA_3P,\\n            INVERSE_GAUSSIAN,\\n            INVERSE_GAUSSIAN_3P,\\n            JOHNSON_SB,\\n            JOHNSON_SU,\\n            KUMARASWAMY,\\n            LAPLACE,\\n            LEVY,\\n            LOGGAMMA,\\n            LOGISTIC,\\n            LOGLOGISTIC,\\n            LOGLOGISTIC_3P,\\n            LOGNORMAL,\\n            MAXWELL,\\n            MOYAL,\\n            NAKAGAMI,\\n            NON_CENTRAL_CHI_SQUARE,\\n            NON_CENTRAL_F,\\n            NON_CENTRAL_T_STUDENT,\\n            NORMAL,\\n            PARETO_FIRST_KIND,\\n            PARETO_SECOND_KIND,\\n            PERT,\\n            POWER_FUNCTION,\\n            RAYLEIGH,\\n            RECIPROCAL,\\n            RICE,\\n            SEMICIRCULAR,\\n            TRAPEZOIDAL,\\n            TRIANGULAR,\\n            T_STUDENT,\\n            T_STUDENT_3P,\\n            UNIFORM,\\n            WEIBULL,\\n            WEIBULL_3P,\\n        ]\\n        if n_jobs == 1:\\n            processing_results = [self.process_distribution(distribution_class) for distribution_class in _ALL_CONTINUOUS_DISTRIBUTIONS]\\n        else:\\n            processing_results = joblib.Parallel(n_jobs=n_jobs)(joblib.delayed(self.process_distribution)(distribution_class) for distribution_class in _ALL_CONTINUOUS_DISTRIBUTIONS)\\n        processing_results = [r for r in processing_results if r is not None]\\n        sorted_results_sse = {distribution: results for distribution, results in sorted(processing_results, key=lambda x: (-x[1][\"n_test_passed\"], x[1][\"sse\"]))}\\n        not_rejected_results = {distribution: results for distribution, results in sorted_results_sse.items() if results[\"n_test_passed\"] > 0}\\n        return sorted_results_sse, not_rejected_results'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_phitter_continuous_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_file = open(\"./production_continuous.py\", \"+w\", encoding=\"utf8\")\n",
    "code_file.write(CODE)\n",
    "code_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_name_code = \"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    path = \"../../continuous/data/data_beta.txt\"\n",
    "    sample_distribution_file = open(path, \"r\")\n",
    "    data = [float(x.replace(\",\", \".\")) for x in sample_distribution_file.read().splitlines()]\n",
    "\n",
    "    phitter_continuous = PHITTER_CONTINUOUS(data)\n",
    "    sorted_results_sse, not_rejected_results = phitter_continuous.fit()\n",
    "\n",
    "    for distribution, results in not_rejected_results.items():\n",
    "        print(f\"Distribution: {distribution}, SSE: {results['sse']}, Aprobados: {results['n_test_passed']}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE += if_name_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_file = open(\"./test_production_continuous.py\", \"+w\", encoding=\"utf8\")\n",
    "code_file.write(CODE)\n",
    "code_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
